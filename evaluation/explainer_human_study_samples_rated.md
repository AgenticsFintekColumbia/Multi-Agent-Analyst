# Explainer Human-Study Evaluation Results

**Evaluation Date:** 2025-11-30  
**Number of Samples:** 16  
**Sampling Method:** Selected recommendations with the highest data completeness (full fundamentals, technicals, and news available)

---

## How We Evaluated the Explainer

We generated explainer outputs for 16 historically rich analyst recommendations and had a human reviewer score each explanation on three criteria:

1. **Plausibility** — does it read like a real sell-side analyst’s reasoning?  
2. **Signal Coverage** — does it reference the key fundamental, technical, and news signals?  
3. **Internal Consistency** — does the final conclusion logically follow from the evidence?

We also checked whether the explanation correctly incorporated all available modalities (fundamentals, technicals, news) in each case.

---

## Mean Scores

- **Plausibility:** 4.81 / 5.0  
- **Signal Coverage:** 4.50 / 5.0  
- **Internal Consistency:** 4.50 / 5.0  

These results indicate that the Explainer produces realistic, data-grounded, and coherent explanations.

---

## Modality Alignment

- **Mentions fundamentals:** 100%  
- **Mentions technicals:** 100%  
- **Mentions news:** 100%  
- **Calls out missing data:** 0% (expected — all samples had complete data)

---

## Data Quality

- **Average data completeness score:** 3.00 / 3.0  
  (All samples contained full fundamental, technical, and news coverage.)

---

## Rating Criteria

- **Plausibility:** 1 = implausible · 5 = highly realistic  
- **Signal Coverage:** 1 = major gaps · 5 = comprehensive  
- **Internal Consistency:** 1 = contradictory · 5 = well-supported  

Modality checklist fields (`mentions_fundamental`, `mentions_technical`, etc.) track whether the explanation uses each data type when available.
